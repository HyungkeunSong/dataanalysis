{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버영화 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, scipy as sp, seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#메인페이지\n",
    "def get_info_main(soup_info):\n",
    "    i = 0\n",
    "    m_rank_v =1\n",
    "\n",
    "    while i<50:\n",
    "        try:\n",
    "            d_date_v = str(soup_info.find_all('p', class_='r_date')[0].get_text().strip().replace('.',''))\n",
    "\n",
    "            m_title_v = soup_info.find_all('div', class_='tit5')[i].get_text().strip()\n",
    "\n",
    "            rate_netizen_v = soup_info.find_all('td', class_='point')[i].get_text()\n",
    "\n",
    "            m_url_raw_v = soup_info.find_all('div', class_='tit5')[i]\n",
    "            m_url_raw_v = m_url_raw_v.a['href']\n",
    "            m_url_v = (url_base + m_url_raw_v).strip()\n",
    "\n",
    "            #리스트에 append\n",
    "            d_date.append(d_date_v)\n",
    "            m_title.append(m_title_v)\n",
    "            m_rank.append(m_rank_v)\n",
    "            rate_netizen.append(rate_netizen_v)\n",
    "            m_url.append(m_url_v)        \n",
    "\n",
    "        except:\n",
    "            print('Under rank 50')\n",
    "            break\n",
    "\n",
    "        #print(i)\n",
    "        m_rank_v += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#서브페이지\n",
    "def get_info_sub(num_info):\n",
    "    i_url = 0\n",
    "\n",
    "    for i_url in range(0,len(df['m_url'])):\n",
    "        html_sub = urlopen(df['m_url'][i_url])\n",
    "        soup_sub = BeautifulSoup(html_sub, 'html.parser')    \n",
    "\n",
    "        #관람객 평점\n",
    "        rate_viewer_raw = soup_sub.find_all('a', class_='ntz_score')\n",
    "        if len(rate_viewer_raw)>0:\n",
    "            rate_viewer_raw = rate_viewer_raw[0].get_text().strip()\n",
    "            if rate_viewer_raw == '관람객 평점 없음':\n",
    "                rate_viewer = np.nan\n",
    "                #print('1:',rate_viewer)\n",
    "            else:\n",
    "                rate_viewer = re.findall('\\S(\\d.\\d{2})', rate_viewer_raw)[0]\n",
    "                #print('1:',rate_viewer)\n",
    "        else:\n",
    "            rate_viewer = np.nan\n",
    "            #print('1:',rate_viewer)\n",
    "\n",
    "        #전문가 평점\n",
    "        rate_spc_raw = soup_sub.find_all('div', class_='spc_score_area')\n",
    "        if len(rate_spc_raw)>0:\n",
    "            rate_spc_raw = rate_spc_raw[0].get_text().strip()\n",
    "            if rate_spc_raw == '전문가 평점 없음':\n",
    "                rate_spc = np.nan\n",
    "                #print('3:',rate_spc)\n",
    "            else:\n",
    "                rate_spc = re.findall('\\s(\\d.\\d{2})', rate_spc_raw)[0]\n",
    "                #print('2:',rate_spc)\n",
    "        else:\n",
    "            rate_spc = np.nan\n",
    "            #print('2:',rate_spc)\n",
    "\n",
    "        #개요(장르)\n",
    "        m_genre_raw = soup_sub.find_all('dl', class_='info_spec')\n",
    "        if len(rate_spc_raw)>0:\n",
    "            m_genre_raw = m_genre_raw[0].find_all('dd')[0].find_all('span')[0].get_text()\n",
    "            m_genre = m_genre_raw.replace('\\n','').replace('\\t','').replace('\\r','').strip()\n",
    "            #print('3:',m_genre)\n",
    "        else:\n",
    "            m_genre = np.nan\n",
    "            #print('3:',m_genre)\n",
    "\n",
    "        #국가\n",
    "        m_country_raw = soup_sub.find_all('dl', class_='info_spec')\n",
    "        if len(m_country_raw)>0:\n",
    "            m_country_raw = m_country_raw[0].find_all('dd')[0].find_all('span')[1].get_text()\n",
    "            m_country = m_country_raw.replace('\\n','').replace('\\t','').replace('\\r','').strip()\n",
    "            #print('4:',m_country)\n",
    "        else:\n",
    "            m_country = np.nan\n",
    "            #print('4:',m_country)\n",
    "\n",
    "        #러닝타임   \n",
    "        m_time_raw = soup_sub.find_all('dl', class_='info_spec')\n",
    "        if len(m_time_raw)>0:\n",
    "            m_time_raw = m_time_raw[0].find_all('dd')[0].find_all('span')[2].get_text()\n",
    "            m_time = m_time_raw.replace('\\n','').replace('\\t','').replace('\\r','').strip()\n",
    "            #print('5:',m_time)\n",
    "        else:\n",
    "            m_time = np.nan\n",
    "            #print('5:',m_time)\n",
    "\n",
    "        #개봉일\n",
    "        m_release_raw = soup_sub.find_all('dl', class_='info_spec')\n",
    "        if len(m_release_raw)>0:\n",
    "            m_release_raw = m_release_raw[0].find_all('dd')[0].find_all('span')[3].get_text()\n",
    "            m_release_raw = m_release_raw.replace('\\n','').replace('\\t','').replace('\\r','').strip()\n",
    "            if '재개봉' in m_release_raw:\n",
    "                m_release = m_release_raw.replace(',  ',' / ')\n",
    "                #print('6:',m_release)\n",
    "            else:\n",
    "                m_release = re.findall('\\d{4}.\\d{2}.\\d{2}', m_release_raw)[0]\n",
    "                #print('6:',m_release)\n",
    "        else:\n",
    "            m_release = np.nan\n",
    "            #print('6:',m_release)\n",
    "\n",
    "        #감독\n",
    "        m_director_raw = soup_sub.find_all('dl', class_='info_spec')\n",
    "        if len(m_director_raw)>0:\n",
    "            m_director_raw = m_director_raw[0].find_all('dd')[1].find_all('p')[0].get_text()\n",
    "            m_director = m_director_raw.replace('\\n','').replace('\\t','').replace('\\r','').strip()\n",
    "            #print('7:',m_director)\n",
    "        else:\n",
    "            m_director = np.nan\n",
    "            #print('7:',m_director)\n",
    "\n",
    "        #누적관객수\n",
    "        m_num_views_raw = soup_sub.find_all('p', class_='count')\n",
    "        if len(m_num_views_raw)>0:\n",
    "            m_num_views_raw = m_num_views_raw[0].get_text()\n",
    "            m_num_views = int(m_num_views_raw.split('명')[0].replace(',',''))\n",
    "            m_num_views_date = m_num_views_raw.split('명')[1].split(' ')[0].replace('(','')  \n",
    "            #print('8:',m_num_views)\n",
    "            #print('9:',m_num_views_date)\n",
    "        else:\n",
    "            m_num_views = np.nan\n",
    "            m_num_views_date = np.nan\n",
    "            #print('8:',m_num_views)\n",
    "            #print('9:',m_num_views_date)\n",
    "            \n",
    "        #데이터프레임에 집어넣기\n",
    "        df.loc[i_url,'rate_viewer'] = rate_viewer \n",
    "        df.loc[i_url,'rate_spc'] = rate_spc\n",
    "        df.loc[i_url,'m_genre'] = m_genre\n",
    "        df.loc[i_url,'m_country'] = m_country\n",
    "        df.loc[i_url,'m_time'] = m_time\n",
    "        df.loc[i_url,'m_release'] = m_release\n",
    "        df.loc[i_url,'m_director'] = m_director\n",
    "        df.loc[i_url,'m_num_views'] = m_num_views\n",
    "        df.loc[i_url,'m_num_views_date'] = m_num_views_date\n",
    "        \n",
    "        #print('Success:', i_url, end=' / ')\n",
    "        time.sleep(random.random()+random.random()*random.random())\n",
    "    print('Success: ', num_info, end=' / ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:  20200427 / Success:  20200428 / Success:  20200429 / "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "\n",
    "pr_m = pd.period_range(start = '20200427', end = None, periods = 3, freq = 'D')           \n",
    "date_list = [v.strftime('%Y%m%d') for v in pr_m]\n",
    "\n",
    "for i_date in date_list:\n",
    "    url_base = 'https://movie.naver.com'\n",
    "    url_sub = '/movie/sdb/rank/rmovie.nhn?sel=cur&tg=0&date={}'.format(i_date)\n",
    "    page = url_base+url_sub\n",
    "    html = urlopen(page)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    d_date = []\n",
    "    m_title = []\n",
    "    m_rank = []\n",
    "    rate_netizen = []\n",
    "    rate_viewer = []\n",
    "    rate_spc = []\n",
    "    m_url = []\n",
    "\n",
    "    #메인페이지\n",
    "    get_info_main(soup)\n",
    "\n",
    "    df = pd.DataFrame({'d_date':d_date, 'm_title':m_title, 'm_rank':m_rank,\n",
    "                       'rate_netizen':rate_netizen, 'm_url':m_url})\n",
    "    #서브페이지\n",
    "    get_info_sub(i_date)\n",
    "    \n",
    "    #df_list에 집어넣기\n",
    "    result_dict = df.to_dict()\n",
    "    df_list.append(result_dict)\n",
    "    del df\n",
    "\n",
    "\n",
    "df_list = [pd.DataFrame(v) for v in df_list]\n",
    "df_movie = pd.concat(df_list)\n",
    "\n",
    "new_order = ['d_date','m_rank','m_title',\n",
    "             'rate_netizen','rate_viewer','rate_spc',\n",
    "             'm_genre','m_country','m_time','m_release','m_director',\n",
    "             'm_num_views','m_num_views_date','m_url']\n",
    "\n",
    "df_movie = df_movie[new_order].reset_index(drop=True)\n",
    "\n",
    "df_movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_movie.head()\n",
    "# df_movie.to_excel('/Users/hyungkeun/Desktop/네이버영화 크롤링/naver_movie_20200427-20200429.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
